{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK+Wxmnu9O7sMdTjc7CkZk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvXqcd1tNfYI",
        "outputId": "92a367b1-e912-475b-ee47-fcae5e829378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.5/238.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44NyY_e2PzPX",
        "outputId": "d3ebd1b9-1da8-4edb-dfb2-70a5154b4d16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.7-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: kaleido, python-multipart\n",
            "Successfully installed kaleido-0.2.1 python-multipart-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "jwV_j92mQUCt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "PqL5vBddQaT_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_GEMINI_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "G5_znBekQdSD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKQzfKANQlgL",
        "outputId": "4be27c61-b965-4bfe-89d9-3ff0c4b941bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " genai.GenerativeModel(\n",
              "   model_name='models/gemini-pro',\n",
              "   generation_config={}.\n",
              "   safety_settings={}\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What are the usecases of LLMs?\")"
      ],
      "metadata": {
        "id": "Novbv_QxQqSr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZsJY4KS4Qv70",
        "outputId": "e47a35e6-63a6-43a3-c107-fad8fd458410"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **1. Natural Language Processing (NLP):**\n> \n> - **Machine Translation:** Translating text from one language to another.\n> - **Text Summarization:** Automatically summarizing long text into a shorter, concise version.\n> - **Sentiment Analysis:** Identifying the sentiment (positive, negative, or neutral) expressed in a piece of text.\n> - **Question Answering:** Answering questions based on the content of a text.\n> - **Chatbots:** Creating conversational AI assistants that can engage in human-like text-based conversations.\n> - **Named Entity Recognition:** Identifying and classifying named entities (e.g., persons, organizations, locations) within a text.\n> - **Part-of-Speech Tagging:** Assigning appropriate grammatical tags (e.g., noun, verb, adjective) to words in a sentence.\n> - **Text Classification:** Categorizing text documents into predefined categories (e.g., news articles, emails, spam).\n> \n> **2. Text Generation:**\n> \n> - **Storytelling:** Generating creative and engaging stories, poems, and other forms of narrative text.\n> - **Report Writing:** Automatically generating reports and summaries from structured data.\n> - **Marketing Copywriting:** Creating marketing and advertising content, such as product descriptions, slogans, and social media posts.\n> - **Legal Document Generation:** Generating legal documents, contracts, and agreements based on specific parameters.\n> - **Code Generation:** Generating code in various programming languages based on natural language instructions.\n> - **Data-to-Text Generation:** Converting structured data into natural language descriptions or summaries.\n> \n> **3. Dialogue and Conversation:**\n> \n> - **Conversational AI:** Developing AI systems that can engage in coherent, natural, and informative conversations with humans.\n> - **Customer Service Chatbots:** Creating AI-powered chatbots that can handle customer inquiries, provide support, and resolve issues.\n> - **Virtual Assistants:** Building virtual assistants that can perform tasks such as scheduling appointments, setting reminders, and providing information.\n> - **Language Learning:** Developing language learning tools that provide interactive conversations and personalized feedback.\n> \n> **4. Information Extraction:**\n> \n> - **Named Entity Extraction:** Extracting specific entities (e.g., persons, organizations, locations) from unstructured text.\n> - **Relation Extraction:** Identifying and extracting relationships between entities within a text.\n> - **Event Extraction:** Extracting information about events, such as their time, location, and participants.\n> - **Fact Extraction:** Extracting factual statements from text documents.\n> - **Knowledge Graph Construction:** Populating knowledge graphs with information extracted from text.\n> \n> **5. Code Generation:**\n> \n> - **Automatic Programming:** Generating code in various programming languages based on natural language instructions.\n> - **Code Completion:** Suggesting code snippets to developers as they type, helping them write code faster and with fewer errors.\n> - **Code Refactoring:** Automatically refactoring code to improve its structure, readability, and maintainability.\n> - **Bug Fixing:** Identifying and fixing bugs in code by analyzing code patterns and identifying potential issues.\n> \n> **6. Healthcare:**\n> \n> - **Medical Diagnosis:** Assisting doctors in diagnosing diseases by analyzing patient data and medical records.\n> - **Drug Discovery:** Identifying potential drug candidates by analyzing large datasets of chemical compounds.\n> - **Personalized Medicine:** Developing personalized treatment plans for patients based on their genetic information and medical history.\n> - **Clinical Trial Design:** Optimizing clinical trial designs to improve efficiency and accuracy.\n> \n> **7. Finance:**\n> \n> - **Financial Analysis:** Analyzing financial data to identify trends, patterns, and anomalies.\n> - **Risk Assessment:** Assessing the risk associated with financial investments and transactions.\n> - **Fraud Detection:** Identifying fraudulent activities and transactions by analyzing financial data.\n> - **Credit Scoring:** Evaluating the creditworthiness of individuals and businesses.\n> \n> **8. Education:**\n> \n> - **Personalized Learning:** Creating personalized learning plans for students based on their individual needs and learning styles.\n> - **Content Generation:** Generating educational content, such as quizzes, assignments, and lesson plans.\n> - **Automated Grading:** Automatically grading assignments, freeing up teachers' time for other tasks.\n> - **Virtual Tutoring:** Providing virtual tutoring and support to students, answering their questions and providing feedback.\n> \n> **9. Creative Arts:**\n> \n> - **Music Composition:** Generating new music compositions in various genres and styles.\n> - **Image Generation:** Creating realistic and diverse images from text descriptions.\n> - **Video Generation:** Generating short videos based on text prompts or storyboards.\n> - **Art Generation:** Creating unique and visually appealing artwork based on text descriptions or artistic styles.\n> \n> **10. Scientific Research:**\n> \n> - **Literature Review:** Summarizing and synthesizing research literature to identify trends, gaps, and potential research directions.\n> - **Hypothesis Generation:** Generating new hypotheses and research questions based on existing data and knowledge.\n> - **Data Analysis:** Analyzing large datasets to identify patterns, relationships, and insights.\n> - **Scientific Paper Writing:** Generating scientific papers and reports, summarizing research findings and conclusions."
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use LangChain to Access Gemini API**"
      ],
      "metadata": {
        "id": "ighu5ddcQ7Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "vc5j6CucRCOt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "PC6RrsCzRITL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"What are the usecases of LLMs?\")"
      ],
      "metadata": {
        "id": "urpmb19_RmJ4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rl72h-NvRs2i",
        "outputId": "5c757e60-29a8-46f5-9272-5550ee99cf5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> 1. **Language Generation:**\n>    - **Creative Writing:** Generating fiction, poetry, scripts, song lyrics, and other creative content.\n>    - **Content Generation:** Automatically creating blog posts, articles, news reports, marketing copy, and product descriptions.\n>    - **Translation:** Translating text from one language to another in a natural and fluent manner.\n>    - **Summarization:** Condensing long documents, articles, or conversations into concise summaries.\n>    - **Speech Recognition and Generation:** Transcribing spoken language into text and generating natural-sounding speech from text.\n> \n> 2. **Conversational AI:**\n>    - **Chatbots and Virtual Assistants:** Developing sophisticated chatbots and virtual assistants that can engage in natural, human-like conversations.\n>    - **Customer Service:** Providing automated customer support, answering questions, resolving issues, and offering personalized recommendations.\n>    - **Information Retrieval:** Answering user queries, providing relevant information, and summarizing knowledge from various sources.\n> \n> 3. **Code Generation:**\n>    - **Programming Assistants:** Helping programmers write code, generate boilerplate code, debug errors, and suggest optimizations.\n>    - **Natural Language Programming:** Translating natural language instructions into executable code, enabling non-programmers to create simple programs.\n> \n> 4. **Machine Translation:**\n>    - **Language Translation:** Translating text and speech from one language to another, preserving context and meaning.\n>    - **Multilingual Communication:** Facilitating communication between people speaking different languages, enabling real-time translation in meetings, presentations, and online conversations.\n> \n> 5. **Text Classification and Generation:**\n>    - **Sentiment Analysis:** Determining the sentiment or emotion expressed in text, such as positive, negative, or neutral.\n>    - **Topic Categorization:** Automatically classifying text into specific categories or topics, such as news, sports, technology, and finance.\n>    - **Text Summarization:** Condensing long text into a concise and informative summary, preserving key points and omitting unnecessary details.\n> \n> 6. **Question Answering:**\n>    - **Factual Question Answering:** Providing factual answers to questions based on a knowledge base or training data.\n>    - **Conversational Question Answering:** Engaging in open-ended conversations, answering questions, and providing additional information related to the topic.\n> \n> 7. **Healthcare Applications:**\n>    - **Medical Diagnosis:** Assisting healthcare professionals in diagnosing diseases by analyzing patient data, symptoms, and medical history.\n>    - **Treatment Planning:** Recommending personalized treatment plans based on patient-specific information, medical guidelines, and evidence-based practices.\n>    - **Drug Discovery:** Screening potential drug candidates, identifying promising compounds, and predicting their interactions with biological targets.\n> \n> 8. **Legal Applications:**\n>    - **Legal Research:** Analyzing legal documents, case law, and statutes to identify relevant information, precedents, and legal arguments.\n>    - **Contract Review:** Examining contracts, identifying potential risks and obligations, and suggesting revisions or improvements.\n>    - **Legal Writing:** Generating legal briefs, pleadings, and other legal documents based on specific instructions and relevant information.\n> \n> 9. **Financial Applications:**\n>    - **Financial Analysis:** Analyzing financial data, generating reports, and identifying trends and patterns to aid investment decisions.\n>    - **Risk Assessment:** Evaluating financial risks, predicting market behavior, and providing insights for portfolio management.\n>    - **Fraud Detection:** Identifying suspicious transactions, detecting anomalies, and flagging potential fraudulent activities.\n> \n> 10. **Scientific Research:**\n>     - **Data Analysis:** Processing and analyzing large datasets, identifying patterns, and generating insights to aid scientific discoveries.\n>     - **Hypothesis Generation:** Proposing new hypotheses and theories based on existing knowledge, data, and observations.\n>     - **Scientific Writing:** Generating scientific reports, papers, and presentations, communicating research findings in a clear and concise manner."
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}